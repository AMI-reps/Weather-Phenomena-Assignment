{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "This assignment requires that you to find **at least** two datasets on the web which are related, and that you visualize these datasets to answer a question with the broad topic of **weather phenomena** (see below) for the region of **Ann Arbor, Michigan, United States**, or **United States** more broadly.\n",
    "\n",
    "You can merge these datasets with data from different regions if you like! For instance, you might want to compare **Ann Arbor, Michigan, United States** to Ann Arbor, USA. In that case at least one source file must be about **Ann Arbor, Michigan, United States**.\n",
    "\n",
    "You are welcome to choose datasets at your discretion, but keep in mind **they will be shared with your peers**, so choose appropriate datasets. Sensitive, confidential, illicit, and proprietary materials are not good choices for datasets for this assignment. You are welcome to upload datasets of your own as well, and link to them using a third party repository such as github, bitbucket, pastebin, etc. Please be aware of the Coursera terms of service with respect to intellectual property.\n",
    "\n",
    "Also, you are welcome to preserve data in its original language, but for the purposes of grading you should provide english translations. You are welcome to provide multiple visuals in different languages if you would like!\n",
    "\n",
    "As this assignment is for the whole course, you must incorporate principles discussed in the first week, such as having as high data-ink ratio (Tufte) and aligning with Cairoâ€™s principles of truth, beauty, function, and insight.\n",
    "\n",
    "Here are the assignment instructions:\n",
    "\n",
    " * State the region and the domain category that your data sets are about (e.g., **Ann Arbor, Michigan, United States** and **weather phenomena**).\n",
    " * You must state a question about the domain category and region that you identified as being interesting.\n",
    " * You must provide at least two links to available datasets. These could be links to files such as CSV or Excel files, or links to websites which might have data in tabular form, such as Wikipedia pages.\n",
    " * You must upload an image which addresses the research question you stated. In addition to addressing the question, this visual should follow Cairo's principles of truthfulness, functionality, beauty, and insightfulness.\n",
    " * You must contribute a short (1-2 paragraph) written justification of how your visualization addresses your stated research question.\n",
    "\n",
    "What do we mean by **weather phenomena**?  For this category you might want to consider seasonal changes, natural disasters, or historical trends.\n",
    "\n",
    "## Tips\n",
    "* Wikipedia is an excellent source of data, and I strongly encourage you to explore it for new data sources.\n",
    "* Many governments run open data initiatives at the city, region, and country levels, and these are wonderful resources for localized data sources.\n",
    "* Several international agencies, such as the [United Nations](http://data.un.org/), the [World Bank](http://data.worldbank.org/), the [Global Open Data Index](http://index.okfn.org/place/) are other great places to look for data.\n",
    "* This assignment requires you to convert and clean datafiles. Check out the discussion forums for tips on how to do this from various sources, and share your successes with your fellow students!\n",
    "\n",
    "## Example\n",
    "Looking for an example? Here's what our course assistant put together for the **Ann Arbor, MI, USA** area using **sports and athletics** as the topic. [Example Solution File](./readonly/Assignment4_example.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My research question: monitor the Ann Arbor, MI monthly normal climate variables (minimum and maximum temperature, precipitation, snowfall) during 1981-2010 compared to the same variables in all US HCN stations (HCN = historical climatological network).\n",
    "\n",
    "-------------\n",
    "The data can be found at:\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/zipcodes-normals-stations.txt\n",
    "this file contains the CODES, ZIP CODES and REGIONS for each station\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/allstations.txt\n",
    "this file contains the CODES, lat, lon, elevation and STATE IDs for each station\n",
    "\n",
    "the variables at each station are at\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/precipitation/mly-snow-normal.txt\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/precipitation/mly-prcp-normal.txt\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/temperature/mly-tmin-normal.txt\n",
    "\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/temperature/mly-tmax-normal.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.dates as mdates\n",
    "import calendar\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcl\n",
    "import matplotlib.colorbar as mcb\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_str = list(calendar.month_name)\n",
    "months_str.append(months_str[0])\n",
    "months_str = months_str[1:-1]\n",
    "my_variables = [\"tmax\", \"tmin\", \"prcp\", \"snow\"] #these are the variables I'm going to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_domains = [\"Ann Arbor, MI\"] # this is the domain where I am going to monitor my climate variables\n",
    "\n",
    "my_region = list(map(lambda x: \" \".join(x.split(\" \")[1:]), my_domains))\n",
    "my_state_ID = list(map(lambda x: x.split(\" \")[0], my_domains))\n",
    "my_region = list(map(lambda x: x.split(\",\")[0], my_domains))\n",
    "my_state_ID = list(map(lambda x: x.split(\",\")[-1][1:], my_domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RQC00666270 00674 Manati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RQC00666361 00662 Isabela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RQC00666390 00687 Morovis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RQC00666514 00783 Corozal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RQC00666805 00718 Naguabo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0   RQC00666270 00674 Manati\n",
       "1  RQC00666361 00662 Isabela\n",
       "2  RQC00666390 00687 Morovis\n",
       "3  RQC00666514 00783 Corozal\n",
       "4  RQC00666805 00718 Naguabo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/zipcodes-normals-stations.txt\n",
    "# this file contains the CODES, ZIP CODES and REGIONS for each station in one line\n",
    "zip_codes = pd.read_table(\"ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/zipcodes-normals-stations.txt\", header= None)\n",
    "zip_codes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RQC00666270</td>\n",
       "      <td>00674</td>\n",
       "      <td>Manati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RQC00666361</td>\n",
       "      <td>00662</td>\n",
       "      <td>Isabela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RQC00666390</td>\n",
       "      <td>00687</td>\n",
       "      <td>Morovis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RQC00666514</td>\n",
       "      <td>00783</td>\n",
       "      <td>Corozal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RQC00666805</td>\n",
       "      <td>00718</td>\n",
       "      <td>Naguabo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CODE    ZIP   Region\n",
       "0  RQC00666270  00674   Manati\n",
       "1  RQC00666361  00662  Isabela\n",
       "2  RQC00666390  00687  Morovis\n",
       "3  RQC00666514  00783  Corozal\n",
       "4  RQC00666805  00718  Naguabo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform data cleaning to put the available information in separate columns\n",
    "zip_codes.rename(columns= {zip_codes.columns[0] : \"All string\"} , inplace = True)\n",
    "zip_codes[\"CODE\"] = list(map(lambda x: x.split(\" \")[0], zip_codes[\"All string\"]))\n",
    "zip_codes[\"ZIP\"] = list(map(lambda x: x.split(\" \")[1], zip_codes[\"All string\"]))\n",
    "zip_codes[\"Region\"] = list(map(lambda x: x.split(\" \")[2:], zip_codes[\"All string\"]))\n",
    "zip_codes[\"Region\"] = zip_codes[\"Region\"].apply(\" \".join)\n",
    "zip_codes.drop([\"All string\"], axis=1, inplace = True)\n",
    "zip_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQC00914000 -14.3167 -170.7667  408.4 AS AASUF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQW00061705 -14.3306 -170.7136    3.7 AS PAGO ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAW00064757  44.2325  -79.7811  246.0 ON EGBER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQC00914080  15.2136  145.7497  252.1 MP CAPIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQC00914801  14.1717  145.2428  179.2 MP ROTA ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          All string\n",
       "0  AQC00914000 -14.3167 -170.7667  408.4 AS AASUF...\n",
       "1  AQW00061705 -14.3306 -170.7136    3.7 AS PAGO ...\n",
       "2  CAW00064757  44.2325  -79.7811  246.0 ON EGBER...\n",
       "3  CQC00914080  15.2136  145.7497  252.1 MP CAPIT...\n",
       "4  CQC00914801  14.1717  145.2428  179.2 MP ROTA ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/allstations.txt\n",
    "# this file contains the CODES, lat, lon, elevation and STATE ID for each station in one line\n",
    "\n",
    "codes = pd.read_table(\"ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/station-inventories/allstations.txt\", header= None)\n",
    "codes.rename(columns= {codes.columns[0] : \"All string\"} , inplace = True)\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform data cleaning to put the information in separate columns\n",
    "codes[\"HCN\"] = codes[\"All string\"].str.find(\"HCN\") > 0\n",
    "codes = codes[codes[\"HCN\"]==True]\n",
    "codes.drop(\"HCN\", axis=1, inplace = True)\n",
    "codes[\"CODE\"] = list(map(lambda x: x.split()[0], codes[\"All string\"]))\n",
    "codes[\"All string\"] = codes[\"All string\"].apply(''.join)\n",
    "codes[\"Lat\"] = list(map(lambda x: x.split()[1], codes[\"All string\"]))\n",
    "codes[\"Lat\"] = codes[\"Lat\"].astype(\"float\")\n",
    "codes[\"All string\"] = list(map(lambda x: x.split()[2:], codes[\"All string\"]))\n",
    "codes[\"All string\"] = codes[\"All string\"].apply(\" \".join)\n",
    "codes[\"Lon\"] = list(map(lambda x: x.split()[0], codes[\"All string\"]))\n",
    "codes[\"Lon\"] = codes[\"Lon\"].astype(\"float\")\n",
    "codes[\"All string\"] = list(map(lambda x: x.split()[1:], codes[\"All string\"]))\n",
    "codes[\"All string\"] = codes[\"All string\"].apply(\" \".join)\n",
    "codes[\"Elev\"] = list(map(lambda x: x.split()[0], codes[\"All string\"])) \n",
    "codes[\"Elev\"] = codes[\"Elev\"].astype(\"float\")\n",
    "codes[\"All string\"] = list(map(lambda x: x.split()[1:], codes[\"All string\"]))\n",
    "codes[\"All string\"] = codes[\"All string\"].apply(\" \".join)\n",
    "codes[\"State ID\"] = list(map(lambda x: x.split()[0], codes[\"All string\"]))\n",
    "codes[\"All string\"] = list(map(lambda x: x.split()[1:], codes[\"All string\"]))\n",
    "codes[\"All string\"] = codes[\"All string\"].apply(\" \".join)\n",
    "# aux = list(map(lambda x, y: ((codes[\"State ID\"] == x) &  (codes[\"All string\"].str.contains(y, case=False)) ), my_state_ID, my_region ))\n",
    "# codes = pd.concat([codes.loc[aux[i][:]==True] for i in range(len(aux))])\n",
    "codes.drop(\"All string\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Elev</th>\n",
       "      <th>State ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00011084</td>\n",
       "      <td>36426</td>\n",
       "      <td>Brewton</td>\n",
       "      <td>31.0581</td>\n",
       "      <td>-87.0547</td>\n",
       "      <td>25.9</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00012813</td>\n",
       "      <td>36532</td>\n",
       "      <td>Fairhope</td>\n",
       "      <td>30.5467</td>\n",
       "      <td>-87.8808</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00013160</td>\n",
       "      <td>35460</td>\n",
       "      <td>Epes</td>\n",
       "      <td>32.8347</td>\n",
       "      <td>-88.1342</td>\n",
       "      <td>38.1</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00013511</td>\n",
       "      <td>36744</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>32.7019</td>\n",
       "      <td>-87.5817</td>\n",
       "      <td>67.1</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00013816</td>\n",
       "      <td>36041</td>\n",
       "      <td>Highland Home</td>\n",
       "      <td>31.8814</td>\n",
       "      <td>-86.2503</td>\n",
       "      <td>132.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CODE    ZIP         Region      Lat      Lon   Elev State ID\n",
       "0  USC00011084  36426        Brewton  31.0581 -87.0547   25.9       AL\n",
       "1  USC00012813  36532       Fairhope  30.5467 -87.8808    7.0       AL\n",
       "2  USC00013160  35460           Epes  32.8347 -88.1342   38.1       AL\n",
       "3  USC00013511  36744     Greensboro  32.7019 -87.5817   67.1       AL\n",
       "4  USC00013816  36041  Highland Home  31.8814 -86.2503  132.0       AL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pd with the common information from the two above pds\n",
    "my_code_reg_pd = pd.merge(zip_codes, codes, how=\"inner\", left_on=\"CODE\", right_on=\"CODE\")\n",
    "my_code_reg_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/\n",
    "# this folder contains files with monthly measurements of the monitored climate variables for each \n",
    "\n",
    "def pd_with_variable(my_string_folder):\n",
    "    \n",
    "    var_aux = pd.read_csv(\"ftp://ftp.ncdc.noaa.gov/pub/data/normals/1981-2010/products/{}-normal.txt\".format(my_string_folder), header = None)\n",
    "    var_aux.rename(columns= {var_aux.columns[0] : \"All string\"} , inplace = True)\n",
    "    var_aux[\"All string\"]= list(map(lambda x: x.split(), var_aux[\"All string\"]))\n",
    "    var_aux[\"All string\"] = var_aux[\"All string\"].apply(\" \".join)\n",
    "    var_aux[\"CODE\"] = list(map(lambda x: x.split(\" \")[0], var_aux[\"All string\"]))\n",
    "    var_aux[\"All string\"] = list(map(lambda x: x.split(\" \")[1:], var_aux[\"All string\"]))\n",
    "    var_aux[\"All string\"] = var_aux[\"All string\"].apply(\" \".join)\n",
    "\n",
    "    for idx_name, cname in enumerate(months_str):\n",
    "        var_aux[cname] = list(map(lambda x: x.split(\" \")[idx_name], var_aux[\"All string\"]))\n",
    "    var_aux.drop(\"All string\",axis=1, inplace=True)\n",
    "    var_aux.set_index(\"CODE\",inplace=True)\n",
    "\n",
    "    for col in var_aux.columns:\n",
    "        var_aux[col] = var_aux[col].map(lambda x: x[0:-1])\n",
    "    var_aux[var_aux.columns] = var_aux[var_aux.columns].astype(int)\n",
    "\n",
    "    var_aux[var_aux==-9999] = np.NaN\n",
    "    var_aux[var_aux==-8888] = np.NaN\n",
    "    var_aux[var_aux==-7777] = 0\n",
    "    var_aux[var_aux==-6666] = np.NaN\n",
    "    var_aux[var_aux==-5555] = np.NaN\n",
    "    my_var = my_string_folder[-4:]\n",
    "    var_aux[\"Var\"] = my_var\n",
    "    var_aux.reset_index(inplace=True)\n",
    "    var_aux.set_index([\"CODE\",\"Var\"], inplace=True)\n",
    "    if (my_var == \"prcp\"): \n",
    "        var_aux = var_aux*0.01 #from README: hundredths of inches for precipitation,\n",
    "    else:\n",
    "        var_aux = var_aux*0.1 # tenths of degrees Fahrenheit, tenths of inches for snowfall, \n",
    "    \n",
    "    if (my_var == \"tmin\") | (my_var ==\"tmax\"):\n",
    "        var_aux = (var_aux-32)* 0.55 # transform from farenheit to Â°C\n",
    "    if (my_var == \"snow\") | (my_var == \"prcp\"):\n",
    "        var_aux = var_aux *2.54 #transform from inches to cm\n",
    "    var_aux.reset_index(inplace=True)\n",
    "    var_aux.set_index(\"CODE\", inplace=True)\n",
    "    return var_aux\n",
    "\n",
    "#\n",
    "my_string_folder_var = [\"temperature/mly-{}\".format(x) for x in [\"tmin\",\"tmax\"]] + [\"precipitation/mly-{}\".format(y) for y in [\"prcp\",\"snow\"]]\n",
    "\n",
    "# create a dataframe with all the CODES and variables, and the monthly measured variables \n",
    "vars_pd_cat = pd.concat([pd_with_variable(x) for x in my_string_folder_var])\n",
    "\n",
    "# create a complete dataframe containing both the information of the monitored variables and all the other\n",
    "# information available about the regions\n",
    "vars_pd = pd.merge(my_code_reg_pd, vars_pd_cat, how=\"inner\",left_on=\"CODE\",right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AQW00061705</th>\n",
       "      <td>tmin</td>\n",
       "      <td>24.915</td>\n",
       "      <td>25.025</td>\n",
       "      <td>25.025</td>\n",
       "      <td>24.915</td>\n",
       "      <td>24.915</td>\n",
       "      <td>24.695</td>\n",
       "      <td>24.365</td>\n",
       "      <td>24.365</td>\n",
       "      <td>24.585</td>\n",
       "      <td>24.695</td>\n",
       "      <td>24.915</td>\n",
       "      <td>24.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAW00064757</th>\n",
       "      <td>tmin</td>\n",
       "      <td>-11.660</td>\n",
       "      <td>-10.670</td>\n",
       "      <td>-6.490</td>\n",
       "      <td>0.715</td>\n",
       "      <td>6.270</td>\n",
       "      <td>11.550</td>\n",
       "      <td>13.860</td>\n",
       "      <td>12.595</td>\n",
       "      <td>8.690</td>\n",
       "      <td>3.355</td>\n",
       "      <td>-1.320</td>\n",
       "      <td>-7.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CQC00914080</th>\n",
       "      <td>tmin</td>\n",
       "      <td>22.770</td>\n",
       "      <td>22.495</td>\n",
       "      <td>22.605</td>\n",
       "      <td>23.045</td>\n",
       "      <td>23.925</td>\n",
       "      <td>23.815</td>\n",
       "      <td>23.705</td>\n",
       "      <td>23.760</td>\n",
       "      <td>23.650</td>\n",
       "      <td>23.595</td>\n",
       "      <td>23.650</td>\n",
       "      <td>23.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CQC00914801</th>\n",
       "      <td>tmin</td>\n",
       "      <td>23.100</td>\n",
       "      <td>22.715</td>\n",
       "      <td>23.155</td>\n",
       "      <td>23.650</td>\n",
       "      <td>23.980</td>\n",
       "      <td>24.255</td>\n",
       "      <td>23.870</td>\n",
       "      <td>23.650</td>\n",
       "      <td>23.540</td>\n",
       "      <td>23.705</td>\n",
       "      <td>23.815</td>\n",
       "      <td>23.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FMC00914395</th>\n",
       "      <td>tmin</td>\n",
       "      <td>22.550</td>\n",
       "      <td>22.605</td>\n",
       "      <td>22.605</td>\n",
       "      <td>22.770</td>\n",
       "      <td>22.825</td>\n",
       "      <td>22.605</td>\n",
       "      <td>22.330</td>\n",
       "      <td>22.275</td>\n",
       "      <td>22.110</td>\n",
       "      <td>22.220</td>\n",
       "      <td>22.110</td>\n",
       "      <td>22.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Var  January  February   March   April     May    June    July  \\\n",
       "CODE                                                                           \n",
       "AQW00061705  tmin   24.915    25.025  25.025  24.915  24.915  24.695  24.365   \n",
       "CAW00064757  tmin  -11.660   -10.670  -6.490   0.715   6.270  11.550  13.860   \n",
       "CQC00914080  tmin   22.770    22.495  22.605  23.045  23.925  23.815  23.705   \n",
       "CQC00914801  tmin   23.100    22.715  23.155  23.650  23.980  24.255  23.870   \n",
       "FMC00914395  tmin   22.550    22.605  22.605  22.770  22.825  22.605  22.330   \n",
       "\n",
       "             August  September  October  November  December  \n",
       "CODE                                                         \n",
       "AQW00061705  24.365     24.585   24.695    24.915    24.915  \n",
       "CAW00064757  12.595      8.690    3.355    -1.320    -7.480  \n",
       "CQC00914080  23.760     23.650   23.595    23.650    23.155  \n",
       "CQC00914801  23.650     23.540   23.705    23.815    23.760  \n",
       "FMC00914395  22.275     22.110   22.220    22.110    22.275  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_pd_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the plot. use different cmaps for the cold/hot variables. \n",
    "qmin = 0.05\n",
    "qmax = 0.95 # avoid outlayers: take only the data between the qmin and qmax quantiles.\n",
    "cmaps = [cm.jet, cm.jet, cm.Blues, cm.Blues]\n",
    "legend_labels = [\"[Â°C]\", \"[Â°C]\", \"[cm]\", \"[cm]\"]\n",
    "titles = [\"TMAX\", \"TMIN\", \"PRECIPITATION\", \"SNOWFALL\"]\n",
    "US_borderlines = pd.read_csv(\"cb_2017_us_state_500k.csv\", sep =\",\", header=None) # US borderlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig, ((ax1,ax2),(ax3, ax4) )= plt.subplots(2,2,figsize=(8,8))\n",
    "my_axes = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "#normalize all colormaps \n",
    "normalize = ([mcl.Normalize(vmin = round(pd.concat([vars_pd.loc[vars_pd[\"Var\"] == my_variables[idx_axes], i] for i in months_str[0:-1]]).quantile(qmin)/10)*10, \n",
    "                            vmax = round(pd.concat([vars_pd.loc[vars_pd[\"Var\"] == my_variables[idx_axes], i] for i in months_str[0:-1]]).quantile(qmax)/10)*10) \n",
    "             for idx_axes in range(len(my_variables))])           \n",
    "fig.suptitle(\"US climate variable normals (1981-2010) \\n\" + months_str[0].upper() , fontsize = 20)\n",
    "\n",
    "sAA = (my_axes[0].scatter(list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[0]),\"Lon\"]),\n",
    "                     list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[0]),\"Lat\"]), \n",
    "                     s = 150, marker = \"*\", edgecolor=\"k\", facecolor=\"w\",\n",
    "                     label = my_region[0] +  \", \" +  my_state_ID[0]))\n",
    "\n",
    "my_axes[0].legend(bbox_to_anchor=(.85, -0.3), loc='lower left', borderaxespad=0. , frameon=False)\n",
    "\n",
    "#create a scatterplot for all 4 variables\n",
    "\n",
    "for idx_axes, ax in enumerate(my_axes):\n",
    "    ax.scatter(US_borderlines.iloc[0,:],US_borderlines.iloc[1,:], s=0.005, c=\"gray\" ) #US borderlines LON, LAT\n",
    "   \n",
    "    ax.axes.set_xlim([-125, -65])\n",
    "    ax.axes.set_ylim([23 ,50])\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_aspect(1.8)\n",
    "   \n",
    "    \n",
    "    s1 = (ax.scatter(list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],\"Lon\"]),\n",
    "                                list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],\"Lat\"]), s = 10, \n",
    "                                 c = list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],months_str[0]]), cmap=cmaps[idx_axes], norm = normalize[idx_axes]))\n",
    "\n",
    "    \n",
    "    sAA = (ax.scatter(list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),\"Lon\"]),\n",
    "                     list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),\"Lat\"]), \n",
    "                     s = 150, marker = \"*\", edgecolor=\"k\",\n",
    "                     c = list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),months_str[0]]), \n",
    "                             cmap=cmaps[idx_axes], norm = normalize[idx_axes]))\n",
    "\n",
    "   \n",
    "    if mpl.__version__[0] == \"3\": \n",
    "        #this does not work with mpl._version=\"2.0.0\" of the jupyter hosted on coursera, but it works with mpl._version=\"3.0.2\" \n",
    "        #so this check is just to avoid errors. \n",
    "        #this piece of code sets the colorbars\n",
    "        axins1 = inset_axes(ax, width=\"30%\",  # width = 50% of parent_bbox width\n",
    "                            height=\"5%\",  # height : 5%\n",
    "                            loc='lower left')\n",
    "        (fig.colorbar(s1, cax=axins1, orientation=\"horizontal\", \n",
    "                     ticks = [round(pd.concat([vars_pd.loc[vars_pd[\"Var\"] == my_variables[idx_axes], i] for i in months_str[0:-1]]).quantile(qmin)/10)*10, \n",
    "                              round(pd.concat([vars_pd.loc[vars_pd[\"Var\"] == my_variables[idx_axes], i] for i in months_str[0:-1]]).quantile(qmax)/10)*10],\n",
    "                     label = legend_labels[idx_axes] ))\n",
    "        axins1.xaxis.set_ticks_position(\"top\")\n",
    "    ax.set_title(titles[idx_axes].upper())\n",
    "    \n",
    "# update the scatterplot with the montly measurements\n",
    "def update(curr):\n",
    "    if curr == len(months_str): \n",
    "        a.event_source.stop()\n",
    "    else:\n",
    "        for idx_axes, ax in enumerate(my_axes):\n",
    "            s1 = (ax.scatter(list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],\"Lon\"]),\n",
    "                                    list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],\"Lat\"]), s = 10, \n",
    "                                     c = list(vars_pd.loc[vars_pd[\"Var\"]==my_variables[idx_axes],months_str[curr]]), cmap=cmaps[idx_axes], norm = normalize[idx_axes]))\n",
    "            sAA = (ax.scatter(list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),\"Lon\"]),\n",
    "                             list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),\"Lat\"]), \n",
    "                             s = 150, marker = \"*\", edgecolor=\"k\",\n",
    "                             c = list(vars_pd.loc[(vars_pd[\"Region\"]==my_region[0]) & \n",
    "                                      (vars_pd[\"State ID\"]==my_state_ID[0]) & \n",
    "                                      (vars_pd[\"Var\"]==my_variables[idx_axes]),months_str[curr]]), \n",
    "                             cmap=cmaps[idx_axes], norm = normalize[idx_axes] ))\n",
    "\n",
    "        fig.suptitle(\"US climate variable normals (1981-2010) \\n \" + months_str[curr].upper(), fontsize = 20)\n",
    "a = animation.FuncAnimation(fig, update, interval=1000)\n",
    "# a.save('US_climate_normals_months.gif', dpi=120, writer='imagemagick')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
